{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMPYLwJ1dZ7Cn0i0kVQlfp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"Q-tKkEj6Olcg","executionInfo":{"status":"ok","timestamp":1727344630675,"user_tz":-330,"elapsed":426,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}}},"outputs":[],"source":["from google.colab import drive"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0xtKHzOO8VT","executionInfo":{"status":"ok","timestamp":1727344659849,"user_tz":-330,"elapsed":25766,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"92e2f14e-577c-4d79-c778-affbb428eb70"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls /content/drive/My\\ Drive/Colab_Notebooks/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNKXOls3O8cA","executionInfo":{"status":"ok","timestamp":1727344705415,"user_tz":-330,"elapsed":416,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"3c124725-3181-465d-e08c-37470e249e97"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["converter.py  downloader.py\tloader1.py  main1.py  __pycache__\n","data\t      IrulaRecon.ipynb\tloader.py   main.py   requirements.txt\n"]}]},{"cell_type":"code","source":["!pip install -r /content/drive/My\\ Drive/Colab_Notebooks/requirements.txt"],"metadata":{"id":"YKGkdYXWQuAf","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1727344681369,"user_tz":-330,"elapsed":13535,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"54bbf3be-6084-4f5b-e1eb-0207141acef6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 1)) (2.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 2)) (2.32.3)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (0.10.2.post1)\n","Collecting pydub (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 4))\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (4.44.2)\n","Collecting datasets (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6))\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 7)) (2.4.1+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 8)) (2.4.1+cu121)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 1)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 1)) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 2)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 2)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 2)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 2)) (2024.8.30)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (1.5.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (0.60.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (1.0.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (0.24.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 5)) (4.66.5)\n","Collecting pyarrow>=15.0.0 (from datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6))\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6))\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting xxhash (from datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6))\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6))\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (3.10.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 7)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 7)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 7)) (3.1.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 6)) (4.0.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (4.3.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 1)) (1.16.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (1.17.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 7)) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 7)) (1.3.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r /content/drive/My Drive/Colab_Notebooks/requirements.txt (line 3)) (2.22)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydub, xxhash, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 pydub-0.25.1 xxhash-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyarrow"]},"id":"bfce24bc1eb745999222a31659d9ebb1"}},"metadata":{}}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"eMcWZ0-cQ-sm","executionInfo":{"status":"ok","timestamp":1727344768706,"user_tz":-330,"elapsed":422,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"c3d79d88-3025-4b7e-d632-743300383fc4"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab_Notebooks'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgBa9n3QRq4H","executionInfo":{"status":"ok","timestamp":1727344766965,"user_tz":-330,"elapsed":513,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"9e18cc8f-db2e-4011-f92b-989272a604fc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["converter.py  downloader.py     loader1.py  main1.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n","\u001b[01;34mdata\u001b[0m/         IrulaRecon.ipynb  loader.py   main.py   requirements.txt\n"]}]},{"cell_type":"code","source":["cd ./drive/My\\ Drive/Colab_Notebooks/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpDu_WRhRxnW","executionInfo":{"status":"ok","timestamp":1727344752723,"user_tz":-330,"elapsed":411,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"a067a9d5-34c9-49bc-98b5-7247b4b9b076"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab_Notebooks\n"]}]},{"cell_type":"code","source":["!python /content/drive/My\\ Drive/Colab_Notebooks/downloader.py"],"metadata":{"id":"W3j4x5VwQuOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/My\\ Drive/Colab_Notebooks/data/downloaded_audio/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzGKFJxaQ-nu","executionInfo":{"status":"ok","timestamp":1727320356352,"user_tz":-330,"elapsed":426,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"8281b886-ef94-4d67-8e09-bc85c82bd858"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Across.mp3  Blue.mp3\t Cloud.mp3\tDilute.mp3\tErase.mp3\tGreen.mp3    Mouth.mp3\n","Act.mp3     Bone.mp3\t Cockroach.mp3\tDo.mp3\t\tExtinguish.mp3\tHair.mp3     Nose.mp3\n","Anklet.mp3  Bow.mp3\t Coffee.mp3\tDownwards.mp3\tFar.mp3\t\tHead.mp3     Out.mp3\n","Arm.mp3     Boy.mp3\t Cold.mp3\tDraw.mp3\tFire.mp3\tHen.mp3      Pain.mp3\n","Ash.mp3     Brother.mp3  Cow.mp3\tEars.mp3\tFlood.mp3\tHoney.mp3    Pebble.mp3\n","Baby.mp3    Buffalo.mp3  Crow.mp3\tEarthquake.mp3\tFly.mp3\t\tIce.mp3\n","Bend.mp3    Butter.mp3\t Darkness.mp3\tEast.mp3\tFood.mp3\tKitchen.mp3\n","Bind.mp3    Catch.mp3\t Demolish.mp3\tEmber.mp3\tFuel.mp3\tMilk.mp3\n","Blow.mp3    Cat.mp3\t Destroy.mp3\tEmpty.mp3\tGather.mp3\tMoth.mp3\n"]}]},{"cell_type":"code","source":["!python /content/drive/My\\ Drive/Colab_Notebooks/converter.py"],"metadata":{"id":"ktCCux6GQuZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/My\\ Drive/Colab_Notebooks/data/converted_audio/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9QwBPCfTQ-k0","executionInfo":{"status":"ok","timestamp":1727320395381,"user_tz":-330,"elapsed":441,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"522c2537-6471-4ed7-f972-d6fd1ccbc749"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Across.wav  Blue.wav\t Cloud.wav\tDilute.wav\tErase.wav\tGreen.wav    Mouth.wav\n","Act.wav     Bone.wav\t Cockroach.wav\tDo.wav\t\tExtinguish.wav\tHair.wav     Nose.wav\n","Anklet.wav  Bow.wav\t Coffee.wav\tDownwards.wav\tFar.wav\t\tHead.wav     Out.wav\n","Arm.wav     Boy.wav\t Cold.wav\tDraw.wav\tFire.wav\tHen.wav      Pain.wav\n","Ash.wav     Brother.wav  Cow.wav\tEars.wav\tFlood.wav\tHoney.wav    Pebble.wav\n","Baby.wav    Buffalo.wav  Crow.wav\tEarthquake.wav\tFly.wav\t\tIce.wav\n","Bend.wav    Butter.wav\t Darkness.wav\tEast.wav\tFood.wav\tKitchen.wav\n","Bind.wav    Catch.wav\t Demolish.wav\tEmber.wav\tFuel.wav\tMilk.wav\n","Blow.wav    Cat.wav\t Destroy.wav\tEmpty.wav\tGather.wav\tMoth.wav\n"]}]},{"cell_type":"code","source":["!python loader.py"],"metadata":{"id":"cizn0_rfQulI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python main.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZpGdzr5Yq0C","executionInfo":{"status":"ok","timestamp":1727322926430,"user_tz":-330,"elapsed":7654,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"c663d6c7-5203-4efb-ae74-9d2649511c8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n","The class this function is called from is 'Wav2Vec2Tokenizer'.\n","/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:720: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n","- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Processed audio file: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Bind.wav, Original size: 56096, New size: 160000\n","Processed audio file: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Extinguish.wav, Original size: 56256, New size: 160000\n","Processed audio file: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Earthquake.wav, Original size: 95909, New size: 160000\n","Processed audio file: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Destroy.wav, Original size: 65216, New size: 160000\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Colab_Notebooks/main.py\", line 54, in <module>\n","    inputs = tokenizer(waveforms.numpy(), return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py\", line 801, in __call__\n","    raise ValueError(f\"Only mono-channel audio is supported for input to {self}\")\n","ValueError: Only mono-channel audio is supported for input to Wav2Vec2Tokenizer(name_or_path='facebook/wav2vec2-base-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}\n"]}]},{"cell_type":"code","source":["import os\n","import torch  # Ensure this import is present\n","import torchaudio\n","from torch.utils.data import Dataset\n","\n","class AudioDataset(Dataset):\n","    def __init__(self, audio_dir, labels):\n","        self.audio_dir = audio_dir\n","        self.labels = labels  # labels is now a list of strings\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # Get the audio file path and label\n","        audio_path = os.path.join(self.audio_dir, f\"{self.labels[idx]}.wav\")  # Use the label directly\n","        waveform, sample_rate = torchaudio.load(audio_path)\n","\n","        label = self.labels[idx]  # Directly use the label string\n","\n","        # Pad or truncate the waveform to a fixed size\n","        target_length = 160000  # Set a target length (for example, 10 seconds at 16kHz)\n","        original_size = waveform.size(1)  # Size before padding/truncating\n","\n","        if original_size < target_length:\n","            # Pad the waveform if it's shorter than the target length\n","            padding = target_length - original_size\n","            waveform = torch.nn.functional.pad(waveform, (0, padding))  # Pad at the end\n","        else:\n","            # Truncate the waveform if it's longer than the target length\n","            waveform = waveform[:, :target_length]\n","\n","        # Debugging output\n","        print(f\"Processed audio file: {audio_path}, Original size: {original_size}, New size: {waveform.size(1)}\")\n","\n","        return waveform, sample_rate, label\n","\n","def custom_collate_fn(batch):\n","    waveforms, sample_rates, labels = zip(*batch)\n","    # Pad sequences in the batch\n","    waveforms_padded = torch.nn.utils.rnn.pad_sequence(waveforms, batch_first=True)\n","    return waveforms_padded, sample_rates, labels\n"],"metadata":{"id":"AcfqHhcwYrUr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from torch.utils.data import DataLoader\n","from loader import AudioDataset, custom_collate_fn\n","from transformers import Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer\n","import torch\n","\n","def create_dataloader(csv_file_path, audio_dir, batch_size=4):\n","    # Load the labels from the CSV file\n","    df = pd.read_csv(csv_file_path)\n","\n","    # Convert 'enWord' column to a list of strings for labels\n","    labels = df['enWord'].tolist()\n","    print(f\"Loaded labels: {labels}\")\n","\n","    # Create the dataset\n","    dataset = AudioDataset(audio_dir, labels)\n","\n","    # Create the DataLoader with custom collate function\n","    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True)\n","\n","    return dataloader\n","\n","\n","# Paths\n","csv_file_path = '/content/drive/My Drive/Colab_Notebooks/data/a.csv'\n","audio_dir = '/content/drive/My Drive/Colab_Notebooks/data/converted_audio/'\n","\n","# Create DataLoader\n","dataloader = create_dataloader(csv_file_path, audio_dir, batch_size=4)\n","\n","# Load pre-trained model and tokenizer\n","tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","\n","# Set model to training mode\n","model.train()\n","\n","# Define optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","\n","# Check if GPU is available and move model to GPU if so\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Example training loop\n","num_epochs = 3\n","for epoch in range(num_epochs):\n","    for batch in dataloader:\n","        # Unpack the batch\n","        waveforms, sample_rates, labels = batch\n","\n","        # Move tensors to the appropriate device\n","        waveforms = waveforms.to(device)\n","\n","        # Fix the dimensions to match what Wav2Vec2 expects (batch_size, sequence_length)\n","        # Right now it seems to have an extra dimension [batch_size, 1, 1, sequence_length]\n","        if waveforms.dim() == 4:  # If it has 4 dimensions\n","            waveforms = waveforms.squeeze(2)  # Remove the 3rd dimension, now it's [batch_size, 1, sequence_length]\n","\n","        # Squeeze to ensure waveform has shape [batch_size, sequence_length] or [batch_size, 1, sequence_length]\n","        waveforms = waveforms.squeeze(1)  # Remove the extra channel dimension if it's not needed\n","\n","        # Prepare the input for the Wav2Vec2 model\n","        inputs = {\"input_values\": waveforms}\n","\n","        # Tokenize the labels (text strings) to get the token IDs\n","        tokenized_labels = tokenizer(list(labels), return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n","\n","        # Forward pass\n","        outputs = model(input_values=inputs[\"input_values\"], labels=tokenized_labels)\n","        loss = outputs.loss\n","\n","        # Backward pass\n","        optimizer.zero_grad()  # Zero gradients\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","\n","        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n","\n","\n","# Save the trained model\n","model.save_pretrained('./trained_model')\n","tokenizer.save_pretrained('./trained_model')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602},"id":"uMwcfwq4YroE","executionInfo":{"status":"error","timestamp":1727345132541,"user_tz":-330,"elapsed":3491,"user":{"displayName":"Anshuman Mishra","userId":"09855565992402104502"}},"outputId":"81c8d824-c5b1-4fe2-c3f1-e813ba470c33"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded labels: ['Bend', 'Bone', 'Cockroach', 'Catch', 'Act', 'Boy', 'Cloud', 'Arm', 'Brother', 'Cow', 'Cold', 'Buffalo', 'Earthquake', 'East', 'Ember', 'Bind', 'Far', 'Destroy', 'Bow', 'Crow', 'Empty', 'Do', 'Anklet', 'Fire', 'Cat', 'Downwards', 'Blue', 'Across', 'Ash', 'Draw', 'Baby', 'Darkness', 'Butter', 'Blow', 'Moth', 'Milk', 'Honey', 'Ice', 'Ears', 'Hen', 'Head', 'Hair', 'Gather', 'Coffee', 'Food', 'Green', 'Flood', 'Fly', 'Erase', 'Nose', 'Mouth', 'Kitchen', 'Pebble', 'Out', 'Pain', 'Fuel', 'Dilute', 'Extinguish', 'Demolish']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n","- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Processed: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Mouth.wav, Original size: 30755, New size: 160000\n","Processed: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Darkness.wav, Original size: 44013, New size: 160000\n"]},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["Processed: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Flood.wav, Original size: 48668, New size: 160000\n","Processed: /content/drive/My Drive/Colab_Notebooks/data/converted_audio/Moth.wav, Original size: 68311, New size: 160000\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [4, 1, 2, 160000]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-a1dd9af64ca4>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenized_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   2226\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Label values must be <= vocab_size: {self.config.vocab_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2228\u001b[0;31m         outputs = self.wav2vec2(\n\u001b[0m\u001b[1;32m   2229\u001b[0m             \u001b[0minput_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1807\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m         \u001b[0mextract_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m         \u001b[0mextract_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 )\n\u001b[1;32m    462\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 304\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    305\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [4, 1, 2, 160000]"]}]}]}